{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "d197xGk3thvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pcj9hEHz_aKn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VesYRQo3lYYB",
        "outputId": "9eda2b09-0255-4f44-9478-c8011c3df3ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ3zZfRg_sRN",
        "outputId": "3eb4c449-d488-44c7-d693-624ff9b89cbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-17 06:17:31--  http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz [following]\n",
            "--2024-02-17 06:17:31--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz [following]\n",
            "--2024-02-17 06:17:32--  https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz [following]\n",
            "--2024-02-17 06:17:33--  https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/octet-stream]\n",
            "Saving to: ‘images.tar.gz.2’\n",
            "\n",
            "images.tar.gz.2     100%[===================>] 755.23M  21.3MB/s    in 37s     \n",
            "\n",
            "2024-02-17 06:18:10 (20.5 MB/s) - ‘images.tar.gz.2’ saved [791918971/791918971]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2024-02-17 06:18:10--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz [following]\n",
            "--2024-02-17 06:18:11--  https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz [following]\n",
            "--2024-02-17 06:18:12--  https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173078 (18M) [application/octet-stream]\n",
            "Saving to: ‘annotations.tar.gz.2’\n",
            "\n",
            "annotations.tar.gz. 100%[===================>]  18.28M  10.5MB/s    in 1.7s    \n",
            "\n",
            "2024-02-17 06:18:14 (10.5 MB/s) - ‘annotations.tar.gz.2’ saved [19173078/19173078]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "\n",
        "input_img_paths = sorted(glob(input_dir + \"/*.jpg\"))\n",
        "target_paths = sorted(glob(target_dir + \"/*.png\"))"
      ],
      "metadata": {
        "id": "UKwBLDbp_sOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentDataset(Dataset):\n",
        "    def __init__(self, image_dir, target_dir, img_size=(200, 200),\n",
        "                 random_state=1337, train=True, transform=None):\n",
        "\n",
        "        all_images_path = sorted(glob(image_dir + \"/*.jpg\"))\n",
        "        all_targets_path = sorted(glob(target_dir + \"/*.png\"))\n",
        "\n",
        "        random.Random(random_state).shuffle(all_images_path)\n",
        "        random.Random(random_state).shuffle(all_targets_path)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        num_val_samples = 1000\n",
        "        if train:\n",
        "            self.images_path = all_images_path[num_val_samples:]\n",
        "            self.targets_path = all_targets_path[num_val_samples:]\n",
        "        else:\n",
        "            self.images_path = all_images_path[:num_val_samples]\n",
        "            self.targets_path = all_targets_path[:num_val_samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_path)\n",
        "\n",
        "    def image_read(self, path):\n",
        "        im = cv2.imread(path)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "        im = cv2.resize(im, self.img_size)\n",
        "        return im\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images_path[idx]\n",
        "        target_path = self.targets_path[idx]\n",
        "        image = self.image_read(image_path)\n",
        "        target = self.image_read(target_path)[:, :, 0]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "        target = torch.from_numpy(target.astype(\"int64\")) - 1  # Change to int64\n",
        "        return image.float(), target"
      ],
      "metadata": {
        "id": "P_LIwQZt_sL1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.dConvs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.dConvs(x)\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.DownSampling = nn.Sequential(DoubleConv(in_channels, out_channels),\n",
        "                                           nn.MaxPool2d(2))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.DownSampling(x)\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.UpSampling = nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
        "                                         DoubleConv(out_channels, out_channels))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.UpSampling(x)\n",
        "\n",
        "class MyUnet(nn.Module):\n",
        "    def __init__(self, input_ch, n_classes):\n",
        "        super().__init__()\n",
        "        self.inputs = [input_ch, 64, 128, 256, 512, 1024]\n",
        "        self.outputs = [1024, 512, 256, 128, 64, n_classes]\n",
        "        self.encode_blocks = nn.ModuleList([DownConv(self.inputs[i], self.inputs[i + 1]) for i in range(len(self.inputs) - 1)])\n",
        "        self.decode_blocks = nn.ModuleList([UpConv(self.outputs[i + 1], self.outputs[i]) for i in range(len(self.outputs) - 1)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        CopyCrop = []\n",
        "        for encode_block in self.encode_blocks:\n",
        "            x = encode_block(x)\n",
        "            CopyCrop.append(x.clone())\n",
        "\n",
        "        for i, decode_block in enumerate(self.decode_blocks):\n",
        "            x = decode_block(x)\n",
        "            x = torch.cat((x, CopyCrop[-i - 1]), dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xvnka2_F_sI-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyUnet(input_ch=3, n_classes=3)\n",
        "num_epochs = 10\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "train_dataset = SegmentDataset(input_dir, target_dir, train=True)\n",
        "val_dataset = SegmentDataset(input_dir, target_dir, train=False)\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "jZkMrGfX_sFv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "rij1Hje_qcU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e517f2f6-c3fe-4aaf-f2bb-260962fd769b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyUnet(\n",
              "  (encode_blocks): ModuleList(\n",
              "    (0): DownConv(\n",
              "      (DownSampling): Sequential(\n",
              "        (0): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (1): DownConv(\n",
              "      (DownSampling): Sequential(\n",
              "        (0): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (2): DownConv(\n",
              "      (DownSampling): Sequential(\n",
              "        (0): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (3): DownConv(\n",
              "      (DownSampling): Sequential(\n",
              "        (0): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "    (4): DownConv(\n",
              "      (DownSampling): Sequential(\n",
              "        (0): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decode_blocks): ModuleList(\n",
              "    (0): UpConv(\n",
              "      (UpSampling): Sequential(\n",
              "        (0): ConvTranspose2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
              "        (1): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): UpConv(\n",
              "      (UpSampling): Sequential(\n",
              "        (0): ConvTranspose2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "        (1): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): UpConv(\n",
              "      (UpSampling): Sequential(\n",
              "        (0): ConvTranspose2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "        (1): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): UpConv(\n",
              "      (UpSampling): Sequential(\n",
              "        (0): ConvTranspose2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "        (1): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): UpConv(\n",
              "      (UpSampling): Sequential(\n",
              "        (0): ConvTranspose2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "        (1): DoubleConv(\n",
              "          (dConvs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "            (3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_history = []\n",
        "validation_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    with tqdm(train_dl, leave=False) as bar:\n",
        "        bar.set_description(f\"[Epoch: {epoch + 1}/{num_epochs}]\")\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(bar):\n",
        "\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            bar.set_postfix(avg_epoch_loss=f\"{sum(losses)/len(losses):.4f}\")\n",
        "    train_history.append(sum(losses)/len(losses))\n",
        "\n",
        "    model.eval()\n",
        "    running_testloss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (test_data, test_label) in enumerate(val_dl):\n",
        "            test_output = model(test_data)\n",
        "            vloss = criterion(test_output, test_label)\n",
        "            running_testloss += vloss.item()\n",
        "        avg_vloss = running_testloss / (i + 1)\n",
        "        validation_history.append(avg_vloss)\n",
        "        if epoch % 10 == 9:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]: loss train: {sum(losses)/len(losses):.3f}, validation: {avg_vloss:.3f}')"
      ],
      "metadata": {
        "id": "mUxVNWwuBvUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZbHyUMVU_r9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IUEPOOCf_r56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iy-ygHUO_rbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}