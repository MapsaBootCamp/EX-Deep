{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.351118333Z",
     "start_time": "2024-01-12T10:16:10.674136383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.2+cpu'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You have been given a partially implemented code for a feed-forward neural network using PyTorch. Your task is to complete the missing parts of the code to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.292793674Z",
     "start_time": "2024-01-12T10:16:12.338914372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/1000, Loss: 1.64325749874115\n",
      "Epoch: 200/1000, Loss: 1.634893774986267\n",
      "Epoch: 300/1000, Loss: 1.6271458864212036\n",
      "Epoch: 400/1000, Loss: 1.6199440956115723\n",
      "Epoch: 500/1000, Loss: 1.6132285594940186\n",
      "Epoch: 600/1000, Loss: 1.606980323791504\n",
      "Epoch: 700/1000, Loss: 1.6011508703231812\n",
      "Epoch: 800/1000, Loss: 1.595696210861206\n",
      "Epoch: 900/1000, Loss: 1.5905665159225464\n",
      "Epoch: 1000/1000, Loss: 1.5857436656951904\n",
      "Predictions: tensor([2, 2, 1, 2, 4, 4, 4, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(\n",
    "            x)  # Complete this line to pass the output of the activation function through the second layer        \n",
    "        # x = # Complete this line to pass the output of the first layer through the activation function\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "label_size = 5\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "\n",
    "# Create the neural network object\n",
    "model = NeuralNetwork(input_size, hidden_size, label_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Generate some dummy data for training\n",
    "train_data = torch.randn(100, input_size)\n",
    "train_labels = torch.randint(label_size, (100,))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    # Complete this line to pass the training data through the model and obtain the predictions\n",
    "    outputs = model(train_data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, train_labels)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Test the trained model\n",
    "test_data = torch.randn(10, input_size)\n",
    "tset_labels = torch.randint(label_size, (10,))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(\n",
    "        test_data)  # Complete this line to pass the test data through the model and obtain the predictions \n",
    "\n",
    "    # Print the predictions\n",
    "    _, predicted = torch.max(test_outputs.data, 1)\n",
    "    print(\"Predictions:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In this coding exercise, you need to implement the training of a deep MLP on the MNIST dataset using PyTorch and manually tune the hyperparameters. Follow the steps below to proceed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the MNIST dataset using torchvision.datasets.MNIST. The dataset contains handwritten digit images, and it can be easily accessed through PyTorch's torchvision module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:19.553723409Z",
     "start_time": "2024-01-12T10:16:19.240045943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahmani/work/envs/ML/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=ToTensor())\n",
    "test_ds = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [50000, 10000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define your deep MLP model. Specify the number of hidden layers, the number of neurons in each layer, and the activation function to be used. You can use the nn.Sequential container to stack the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T11:33:52.629564709Z",
     "start_time": "2024-01-12T11:33:52.587480483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (layer_1): Linear(in_features=100, out_features=100, bias=True)\n  (act_fn_1): SiLU()\n  (layer_2): Linear(in_features=100, out_features=50, bias=True)\n  (act_fn_2): SiLU()\n  (layer_3): Linear(in_features=50, out_features=25, bias=True)\n  (act_fn_3): SiLU()\n  (layer_4): Linear(in_features=25, out_features=15, bias=True)\n  (act_fn_4): SiLU()\n  (layer_5): Linear(in_features=15, out_features=14, bias=True)\n  (act_fn_5): SiLU()\n  (layer_6): Linear(in_features=14, out_features=13, bias=True)\n  (act_fn_6): SiLU()\n  (layer7): Linear(in_features=13, out_features=10, bias=True)\n)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, fan_in, fan_out=10, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bias = bias\n",
    "        self.w = nn.Parameter(torch.empty(fan_out, fan_in))\n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.empty(fan_out))\n",
    "        self.reset_params()\n",
    "\n",
    "        self.layer_1 = nn.Linear(fan_in, 100)\n",
    "        self.act_fn_1 = nn.SiLU()  #nn.ReLU()\n",
    "\n",
    "        self.layer_2 = nn.Linear(100, 50)\n",
    "        self.act_fn_2 = nn.SiLU()  #nn.SELU()\n",
    "\n",
    "        self.layer_3 = nn.Linear(50, 25)\n",
    "        self.act_fn_3 = nn.SiLU()  #nn.GELU()\n",
    "\n",
    "        self.layer_4 = nn.Linear(25, 15)\n",
    "        self.act_fn_4 = nn.SiLU()  #nn.CELU()\n",
    "\n",
    "        self.layer_5 = nn.Linear(15, 14)\n",
    "        self.act_fn_5 = nn.SiLU()  #nn.ReLU6()\n",
    "\n",
    "        self.layer_6 = nn.Linear(14, 13)\n",
    "        self.act_fn_6 = nn.SiLU()\n",
    "\n",
    "        self.layer7 = nn.Linear(13, 10)\n",
    "        # self.softmax = nn.Softmax()\n",
    "\n",
    "    def reset_params(self):\n",
    "        nn.init.kaiming_normal_(self.w, nonlinearity=\"leaky_relu\")\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.b, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.act_fn_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.act_fn_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.act_fn_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.act_fn_4(x)\n",
    "        x = self.layer_5(x)\n",
    "        x = self.act_fn_5(x)\n",
    "        x = self.layer_6(x)\n",
    "        x = self.act_fn_6(x)\n",
    "        # x=  self.softmax(x)\n",
    "        x = self.layer7(x, )\n",
    "        # x=  self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(fan_in=100)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up the training loop and the hyperparameters. You can use the CrossEntropyLoss as the loss function and the Stochastic Gradient Descent (SGD) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:57:06.374280156Z",
     "start_time": "2024-01-12T10:57:06.329759268Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create data loaders\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"./data\", train=False, download=False, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "# Create an instance of the model\n",
    "model = MLP(fan_in=784)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model by iterating over the training dataset for the specified number of epochs. Compute the loss, perform backpropagation, and update the model's parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:28:46.600858992Z",
     "start_time": "2024-01-12T10:27:43.758525770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.307936191558838\n",
      "Epoch [2/10], Loss: 2.269987106323242\n",
      "Epoch [3/10], Loss: 2.2662854194641113\n",
      "Epoch [4/10], Loss: 2.3243508338928223\n",
      "Epoch [5/10], Loss: 2.371204137802124\n",
      "Epoch [6/10], Loss: 2.316641092300415\n",
      "Epoch [7/10], Loss: 2.315112829208374\n",
      "Epoch [8/10], Loss: 2.342919111251831\n",
      "Epoch [9/10], Loss: 2.3066067695617676\n",
      "Epoch [10/10], Loss: 2.305234909057617\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "    for images, labels in train_loader:\n",
    "        # Flatten the images\n",
    "        images = images.view(-1, 784)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the trained model on the test dataset and calculate the accuracy (Please take a moment to consider the code below!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:36:55.873846479Z",
     "start_time": "2024-01-12T10:36:55.248045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.80%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 784)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manually tune the hyperparameters, such as the learning rate, by experimenting with different values and observing the performance. You can also search for the optimal learning rate by using techniques like learning rate range test, where you gradually increase the learning rate and monitor the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T12:19:49.229149289Z",
     "start_time": "2024-01-12T12:19:49.181985922Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def training_loop(epochs, train_loader, optimizer, model, criterion):\n",
    "    for epoch_ in range(epochs):\n",
    "        model.train(True)\n",
    "        for images_, labels_ in train_loader:\n",
    "            # Flatten the images_\n",
    "            images_ = images_.view(-1, 784)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output_ = model(images_)\n",
    "\n",
    "            loss_ = criterion(output_, labels_)\n",
    "            # Backward pass and optimization\n",
    "            loss_.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch_ + 1}/{epochs}], Loss: {loss_.item()}')\n",
    "\n",
    "\n",
    "def evaluation(test_loader, model, ):\n",
    "    correct_ = 0\n",
    "    total_ = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images_, labels_ in test_loader:\n",
    "            images_ = images_.view(-1, 784)\n",
    "            outputs_ = model(images_)\n",
    "            _, predicted_ = torch.max(outputs_.data, 1)\n",
    "            total_ += labels_.size(0)\n",
    "            correct_ += (predicted_ == labels_).sum().item()\n",
    "\n",
    "    accuracy_ = 100 * correct_ / total_\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1444414258003235\n",
      "Epoch [2/10], Loss: 0.10363541543483734\n",
      "Epoch [3/10], Loss: 0.5580748319625854\n",
      "Epoch [4/10], Loss: 0.14898644387722015\n",
      "Epoch [5/10], Loss: 0.059083160012960434\n",
      "Epoch [6/10], Loss: 0.006887165363878012\n",
      "Epoch [7/10], Loss: 0.10662557184696198\n",
      "Epoch [8/10], Loss: 0.12871822714805603\n",
      "Epoch [9/10], Loss: 1.435640811920166\n",
      "Epoch [10/10], Loss: 1.1753860712051392\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01  # 0.01 no softmax = 84% with softmax = 28% #& 0.1=86%(best) #&  0.1 no softmax =11.35% # 0 = 9.8%\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model = MLP(fan_in=784)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(epochs, train_loader, optimizer, model, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:20:53.825267241Z",
     "start_time": "2024-01-12T12:19:55.483278308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.19%\n"
     ]
    }
   ],
   "source": [
    "evaluation(test_loader, model, )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:21:21.903058523Z",
     "start_time": "2024-01-12T12:21:21.017405202Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In this coding exercise, you'll have an opportunity to explore the behavior of a deep neural network trained on the CIFAR10 image dataset. Follow the steps below:\n",
    "\n",
    "* a. Construct a deep neural network (DNN) using 20 hidden layers, each comprising 100 neurons. To facilitate this exploration, employ the Swish activation function for each layer. Utilize nn.ModuleList to manage the layers effectively.\n",
    "\n",
    "* b. Load the CIFAR10 dataset for training your network. Utilize the appropriate function, such as torchvision.datasets.CIFAR10. The dataset consists of 60,000 color images, with dimensions of 32Ã—32 pixels. It is divided into 50,000 training samples and 10,000 testing samples. With 10 classes in the dataset, ensure that your network has a softmax output layer comprising 10 neurons. When modifying the model's architecture or hyperparameters, conduct a search to identify an appropriate learning rate. Implement early stopping during training and employ the Nadam optimization algorithm.\n",
    "\n",
    "* c. Experiment by adding batch normalization to your network. Compare the learning curves obtained with and without batch normalization. Analyze whether the model converges faster with batch normalization and observe any improvements in its performance. Additionally, assess the impact of batch normalization on training speed.\n",
    "\n",
    "* d. As an additional experiment, substitute batch normalization with SELU (Scaled Exponential Linear Units). Make the necessary adjustments to ensure the network self-normalizes. This involves standardizing the input features, initializing the network's weights using LeCun normal initialization (nn.init.kaiming_normal_), and ensuring that the DNN consists solely of dense layers. Observe the effects of utilizing SELU activation and self-normalization on the network's training stability and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T11:42:52.304978587Z",
     "start_time": "2024-01-12T11:42:52.263116112Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "CIFModel(\n  (layers): ModuleList(\n    (0): Linear(in_features=1024, out_features=1014, bias=True)\n    (1): Linear(in_features=512, out_features=507, bias=True)\n    (2): Linear(in_features=341, out_features=338, bias=True)\n    (3): Linear(in_features=256, out_features=253, bias=True)\n    (4): Linear(in_features=204, out_features=202, bias=True)\n    (5): Linear(in_features=170, out_features=169, bias=True)\n    (6): Linear(in_features=146, out_features=144, bias=True)\n    (7): Linear(in_features=128, out_features=126, bias=True)\n    (8): Linear(in_features=113, out_features=112, bias=True)\n    (9): Linear(in_features=102, out_features=101, bias=True)\n    (10): Linear(in_features=93, out_features=92, bias=True)\n    (11): Linear(in_features=85, out_features=84, bias=True)\n    (12): Linear(in_features=78, out_features=78, bias=True)\n    (13): Linear(in_features=73, out_features=72, bias=True)\n    (14): Linear(in_features=68, out_features=67, bias=True)\n    (15): Linear(in_features=64, out_features=63, bias=True)\n    (16): Linear(in_features=60, out_features=59, bias=True)\n    (17): Linear(in_features=56, out_features=56, bias=True)\n    (18): Linear(in_features=53, out_features=53, bias=True)\n    (19): Linear(in_features=53, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CIFModel(nn.Module):\n",
    "    def __init__(self, fan_in, fan_out=10, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bias = bias\n",
    "        self.w = nn.Parameter(torch.empty(fan_out, fan_in))\n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.empty(fan_out))\n",
    "        self.reset_params()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(\n",
    "                    int(fan_in / i),\n",
    "                    int((fan_in - 10) / i if (fan_in - 10) / i > 15 else 15)\n",
    "                ) for i in range(1,20)\n",
    "            ]\n",
    "        )\n",
    "        self.layers.add_module(name='final_layer',module=nn.Linear(self.layers[-1].out_features, 10))\n",
    "\n",
    "    def reset_params(self):\n",
    "        nn.init.kaiming_normal_(self.w, nonlinearity=\"leaky_relu\")\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.b, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        F.linear(x, self.w, self.b)\n",
    "cif_model = CIFModel(fan_in=32*32 , fan_out=10, bias=True)\n",
    "cif_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T11:46:01.005473407Z",
     "start_time": "2024-01-12T11:46:00.964400464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "\n",
    "# Create data loaders\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"./data\", train=False, download=False, transform=ToTensor())\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MLP(fan_in=784)\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:13:51.953947431Z",
     "start_time": "2024-01-12T12:13:51.901691623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.10131277143955231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m      8\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mtraining_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[59], line 6\u001B[0m, in \u001B[0;36mtraining_loop\u001B[0;34m(epochs, train_loader, optimizer, model, criterion)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      5\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images_, labels_ \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;66;03m# Flatten the images_\u001B[39;00m\n\u001B[1;32m      8\u001B[0m         images_ \u001B[38;5;241m=\u001B[39m images_\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m784\u001B[39m)\n\u001B[1;32m     10\u001B[0m         \u001B[38;5;66;03m# Zero the gradients\u001B[39;00m\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/mnist.py:145\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    142\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 145\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/transforms/functional.py:166\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# handle PIL Image\u001B[39;00m\n\u001B[1;32m    165\u001B[0m mode_to_nptype \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint32, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint16, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mfloat32}\n\u001B[0;32m--> 166\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_to_nptype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    169\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01  # 0.01 no softmax = 84% with softmax = 28% #& 0.1=86%(best) #&  0.1 no softmax =11.35% # 0 = 9.8%\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model = CIFModel(fan_in=32*32 , fan_out=10, bias=True) #(fan_in=784)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(epochs, train_loader, optimizer, model, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:14:03.579357659Z",
     "start_time": "2024-01-12T12:13:52.784329958Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A Construct a deep neural network (DNN) with Swish activation function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(DeepNeuralNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(Swish())\n",
    "            input_size = hidden_size\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:32:23.921680234Z",
     "start_time": "2024-01-12T12:32:23.892472480Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B Load CIFAR10 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/170498071 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tqdm' object does not support the context manager protocol",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# b. Load CIFAR10 dataset\u001B[39;00m\n\u001B[1;32m      2\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mToTensor(), transforms\u001B[38;5;241m.\u001B[39mNormalize((\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m), (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m))])\n\u001B[0;32m----> 4\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCIFAR10\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mCIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[1;32m      7\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/cifar.py:65\u001B[0m, in \u001B[0;36mCIFAR10.__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain \u001B[38;5;241m=\u001B[39m train  \u001B[38;5;66;03m# training set or test set\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity():\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/cifar.py:139\u001B[0m, in \u001B[0;36mCIFAR10.download\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFiles already downloaded and verified\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m \u001B[43mdownload_and_extract_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtgz_md5\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/utils.py:434\u001B[0m, in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m filename:\n\u001B[1;32m    432\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(url)\n\u001B[0;32m--> 434\u001B[0m \u001B[43mdownload_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    436\u001B[0m archive \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(download_root, filename)\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchive\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mextract_root\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/utils.py:144\u001B[0m, in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m url \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m fpath)\n\u001B[0;32m--> 144\u001B[0m     \u001B[43m_urlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mURLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m url[:\u001B[38;5;241m5\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/utils.py:48\u001B[0m, in \u001B[0;36m_urlretrieve\u001B[0;34m(url, filename, chunk_size)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_urlretrieve\u001B[39m(url: \u001B[38;5;28mstr\u001B[39m, filename: \u001B[38;5;28mstr\u001B[39m, chunk_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT})) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[0;32m---> 48\u001B[0m         \u001B[43m_save_response_content\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/envs/ML/lib/python3.11/site-packages/torchvision/datasets/utils.py:36\u001B[0m, in \u001B[0;36m_save_response_content\u001B[0;34m(content, destination, length)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_save_response_content\u001B[39m(\n\u001B[1;32m     32\u001B[0m     content: Iterator[\u001B[38;5;28mbytes\u001B[39m],\n\u001B[1;32m     33\u001B[0m     destination: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     34\u001B[0m     length: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     35\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 36\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdestination\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# filter out keep-alive new chunks\u001B[39;49;00m\n\u001B[1;32m     39\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'tqdm' object does not support the context manager protocol"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Create the model\n",
    "input_size = 32 * 32 * 3  # CIFAR10 image dimensions\n",
    "hidden_size = 100\n",
    "output_size = 10  # Number of classes in CIFAR10\n",
    "num_layers = 20\n",
    "\n",
    "model = DeepNeuralNetwork(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.Nadam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_accuracy = 0.0\n",
    "patience = 5\n",
    "current_patience = 0\n",
    "\n",
    "for epoch in range(50):  # Set a suitable number of epochs\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.view(-1, input_size))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs.view(-1, input_size))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}, Accuracy: {accuracy}')\n",
    "\n",
    "    # Early stopping\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        current_patience = 0\n",
    "    else:\n",
    "        current_patience += 1\n",
    "        if current_patience >= patience:\n",
    "            print(\"Early stopping. Best accuracy:\", best_accuracy)\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:32:43.273799197Z",
     "start_time": "2024-01-12T12:32:39.765037395Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### C Add batch normalization and compare learning curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_layer(x)\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m---> 20\u001B[0m model_with_batchnorm \u001B[38;5;241m=\u001B[39m DNNWithBatchNorm(input_size, hidden_size, \u001B[43moutput_size\u001B[49m, num_layers)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Training loop with batch normalization\u001B[39;00m\n\u001B[1;32m     23\u001B[0m optimizer_with_batchnorm \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mNadam(model_with_batchnorm\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'output_size' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class DNNWithBatchNorm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(DNNWithBatchNorm, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(Swish())\n",
    "            input_size = hidden_size\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "model_with_batchnorm = DNNWithBatchNorm(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# Training loop with batch normalization\n",
    "optimizer_with_batchnorm = optim.Nadam(model_with_batchnorm.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(50):  # Set a suitable number of epochs\n",
    "    model_with_batchnorm.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_with_batchnorm.zero_grad()\n",
    "        outputs = model_with_batchnorm(inputs.view(-1, input_size))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_with_batchnorm.step()\n",
    "\n",
    "    # Validation\n",
    "    model_with_batchnorm.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_with_batchnorm(inputs.view(-1, input_size))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}, Accuracy with BatchNorm: {accuracy}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T12:32:51.433675281Z",
     "start_time": "2024-01-12T12:32:51.391030732Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### D Substitute batch normalization with SELU activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class DNNWithSELU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(DNNWithSELU, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.SELU())\n",
    "            input_size = hidden_size\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Initialize weights with LeCun normal initialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='selu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model_with_selu = DNNWithSELU(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "model_with_selu.apply(weights_init)\n",
    "\n",
    "# Training loop with SELU activation\n",
    "optimizer_with_selu = optim.Nadam(model_with_selu.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(50):  # Set a suitable number of epochs\n",
    "    model_with_selu.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_with_selu.zero_grad()\n",
    "        outputs = model_with_selu(inputs.view(-1, input_size))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_with_selu.step()\n",
    "\n",
    "    # Validation\n",
    "    model_with_selu.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_with_selu(inputs.view(-1, input_size))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}, Accuracy with SELU: {accuracy}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
